{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "28f8d753",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n",
      "GPU: Quadro P2200\n",
      "Memory: 5.37 GB\n"
     ]
    }
   ],
   "source": [
    "# =========================\n",
    "# 1. é…ç½®åŒº(åªæ”¹è¿™é‡Œ)\n",
    "# =========================\n",
    "\n",
    "import os\n",
    "import numpy as np\n",
    "import torch\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# æ …æ ¼è·¯å¾„\n",
    "DAY_TIFS = [\n",
    "    r\"H:\\Landsat_NL_Mector_90m_zscore\\Landsat_RED_2020_90m_zscore.tif\",\n",
    "    r\"H:\\Landsat_NL_Mector_90m_zscore\\Landsat_GREEN_2020_90m_zscore.tif\",\n",
    "    r\"H:\\Landsat_NL_Mector_90m_zscore\\Landsat_BLUE_2020_90m_zscore.tif\",\n",
    "    r\"H:\\Landsat_NL_Mector_90m_zscore\\Landsat_NIR_2020_90m_zscore.tif\",\n",
    "    r\"H:\\Landsat_NL_Mector_90m_zscore\\Landsat_SWIR1_2020_90m_zscore.tif\",\n",
    "    r\"H:\\Landsat_NL_Mector_90m_zscore\\Landsat_SWIR2_2020_90m_zscore.tif\",\n",
    "    r\"H:\\Landsat_NL_Mector_90m_zscore\\Landsat_TEMP1_2020_90m_zscore.tif\",\n",
    "]\n",
    "NIGHT_TIF = r\"H:\\Landsat_NL_Mector_90m_zscore\\VIIRS_2020_90m_zscore.tif\"\n",
    "\n",
    "# æ ·æœ¬çŸ¢é‡\n",
    "LABEL_SHP = r\"H:\\sample_2020\\Sample_2020.shp\"\n",
    "\n",
    "# å››ä¸ªç»„æˆæ¯”ä¾‹å­—æ®µ\n",
    "TARGET_FIELDS = [\"F\", \"F_NF\", \"NF_F\", \"NF\"]\n",
    "\n",
    "# è¾“å‡ºç›®å½•\n",
    "OUT_DIR = r\"H:\\model_outputs_2020_deep\"\n",
    "os.makedirs(OUT_DIR, exist_ok=True)\n",
    "\n",
    "# è®­ç»ƒè¶…å‚\n",
    "PATCH_SIZE = 64\n",
    "BATCH_SIZE = 64\n",
    "EPOCHS = 100\n",
    "LEARNING_RATE = 1e-3\n",
    "WEIGHT_DECAY = 1e-5  # L2æ­£åˆ™\n",
    "\n",
    "# ç±»ä¼¼è®ºæ–‡çš„å‡ ç§æ•°æ®æ¯”ä¾‹\n",
    "FRACTIONS = [0.05, 0.10, 0.25, 0.50, 1.00]\n",
    "\n",
    "# è¦è·‘å“ªç§æ¨¡å‹\n",
    "RUN_DAY = False\n",
    "RUN_NIGHT = False\n",
    "RUN_FUSION = True\n",
    "\n",
    "DEVICE = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "print(f\"Using device: {DEVICE}\")\n",
    "if torch.cuda.is_available():\n",
    "    print(f\"GPU: {torch.cuda.get_device_name(0)}\")\n",
    "    print(f\"Memory: {torch.cuda.get_device_properties(0).total_memory / 1e9:.2f} GB\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e9e6c8e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =========================\n",
    "# 2. æ•°æ®é›†(æ”¹è¿›ç‰ˆ)\n",
    "# =========================\n",
    "import rasterio\n",
    "import geopandas as gpd\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "class PatchPointDataset(Dataset):\n",
    "    \"\"\"\n",
    "    æ”¹è¿›ç‚¹:\n",
    "    1. é¢„ç­›æœ‰æ•ˆæ ·æœ¬\n",
    "    2. æ”¯æŒæ•°æ®å¢å¼º\n",
    "    3. ç¡®ä¿æ ‡ç­¾æ˜¯ä¸€ä¸ª4ç»´ç»„æˆå¹¶å½’ä¸€åŒ–\n",
    "    \"\"\"\n",
    "    def __init__(self, shp_path, day_paths, night_path, target_fields, \n",
    "                 patch=64, augment=False):\n",
    "        self.gdf = gpd.read_file(shp_path).reset_index(drop=True)\n",
    "        self.day_srcs = [rasterio.open(p) for p in day_paths]\n",
    "        self.night_src = rasterio.open(night_path)\n",
    "        self.target_fields = target_fields\n",
    "        self.patch = patch\n",
    "        self.augment = augment\n",
    "        \n",
    "        self.valid_idx = []\n",
    "        hpatch = self.patch // 2\n",
    "        first_src = self.day_srcs[0]\n",
    "\n",
    "        print(\"â³ æ­£åœ¨æ£€æŸ¥å“ªäº›æ ·æœ¬åœ¨å½±åƒä¸Šæœ‰å€¼...\")\n",
    "        for idx, row in self.gdf.iterrows():\n",
    "            try:\n",
    "                geom = row.geometry\n",
    "                if geom is None or geom.is_empty:\n",
    "                    continue\n",
    "                if geom.geom_type != \"Point\":\n",
    "                    geom = geom.centroid\n",
    "                x, y = geom.x, geom.y\n",
    "                r, c = rasterio.transform.rowcol(first_src.transform, x, y)\n",
    "                \n",
    "                # è¾¹ç•Œæ£€æŸ¥\n",
    "                if r < hpatch or c < hpatch or \\\n",
    "                   r >= first_src.height - hpatch or c >= first_src.width - hpatch:\n",
    "                    continue\n",
    "                \n",
    "                window = rasterio.windows.Window(c - hpatch, r - hpatch, \n",
    "                                                self.patch, self.patch)\n",
    "\n",
    "                ok = True\n",
    "                for src in self.day_srcs:\n",
    "                    arr = src.read(1, window=window, boundless=True, masked=True)\n",
    "                    if arr.mask.all() or np.isnan(arr.filled(0)).all():\n",
    "                        ok = False\n",
    "                        break\n",
    "                \n",
    "                if ok:\n",
    "                    narr = self.night_src.read(1, window=window, boundless=True, masked=True)\n",
    "                    if narr.mask.all() or np.isnan(narr.filled(0)).all():\n",
    "                        ok = False\n",
    "                \n",
    "                # æ ‡ç­¾æ£€æŸ¥\n",
    "                if ok:\n",
    "                    vals = [row[f] for f in self.target_fields]\n",
    "                    if any(v is None or (isinstance(v, float) and np.isnan(v)) for v in vals):\n",
    "                        ok = False\n",
    "                \n",
    "                if ok:\n",
    "                    self.valid_idx.append(idx)\n",
    "                    \n",
    "            except Exception as e:\n",
    "                print(f\"Warning: Sample {idx} failed: {e}\")\n",
    "                continue\n",
    "\n",
    "        print(f\"âœ… å¯ç”¨æ ·æœ¬æ•°: {len(self.valid_idx)} / {len(self.gdf)}\")\n",
    "        if len(self.valid_idx) == 0:\n",
    "            raise RuntimeError(\"æ²¡æœ‰å¯ç”¨æ ·æœ¬,è¯·æ£€æŸ¥çŸ¢é‡å’Œæ …æ ¼æ˜¯å¦å¯¹é½ã€‚\")\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.valid_idx)\n",
    "\n",
    "    def __getitem__(self, i):\n",
    "        real_idx = self.valid_idx[i]\n",
    "        row = self.gdf.iloc[real_idx]\n",
    "        geom = row.geometry\n",
    "        if geom.geom_type != \"Point\":\n",
    "            geom = geom.centroid\n",
    "        x, y = geom.x, geom.y\n",
    "\n",
    "        r, c = rasterio.transform.rowcol(self.day_srcs[0].transform, x, y)\n",
    "        half = self.patch // 2\n",
    "        window = rasterio.windows.Window(c - half, r - half, self.patch, self.patch)\n",
    "\n",
    "        # æ—¥é—´æ ˆ\n",
    "        day_stack = []\n",
    "        for src in self.day_srcs:\n",
    "            arr = src.read(1, window=window, boundless=True, masked=True)\n",
    "            day_stack.append(arr.filled(0).astype(np.float32))\n",
    "        day = np.stack(day_stack, axis=0)\n",
    "\n",
    "        # å¤œé—´\n",
    "        night_arr = self.night_src.read(1, window=window, boundless=True, masked=True)\n",
    "        night = np.expand_dims(night_arr.filled(0).astype(np.float32), axis=0)\n",
    "\n",
    "        # æ•°æ®å¢å¼º\n",
    "        if self.augment:\n",
    "            if np.random.rand() > 0.5:\n",
    "                day = np.flip(day, axis=1).copy()\n",
    "                night = np.flip(night, axis=1).copy()\n",
    "            if np.random.rand() > 0.5:\n",
    "                day = np.flip(day, axis=2).copy()\n",
    "                night = np.flip(night, axis=2).copy()\n",
    "            k = np.random.randint(0, 4)\n",
    "            if k > 0:\n",
    "                day = np.rot90(day, k, axes=(1, 2)).copy()\n",
    "                night = np.rot90(night, k, axes=(1, 2)).copy()\n",
    "\n",
    "        # æ ‡ç­¾\n",
    "        vals = []\n",
    "        for f in self.target_fields:\n",
    "            v = row[f]\n",
    "            v = 0.0 if (v is None or (isinstance(v, float) and np.isnan(v))) else v\n",
    "            vals.append(float(v))\n",
    "        y = np.array(vals, dtype=np.float32)\n",
    "        \n",
    "        # å½’ä¸€åŒ–æˆç»„æˆ\n",
    "        s = y.sum()\n",
    "        if s > 1e-6:\n",
    "            y = y / s\n",
    "        else:\n",
    "            y = np.array([1.0] + [0.0]*(len(self.target_fields)-1), dtype=np.float32)\n",
    "\n",
    "        return {\n",
    "            \"day\": torch.from_numpy(day),\n",
    "            \"night\": torch.from_numpy(night),\n",
    "            \"y\": torch.from_numpy(y),\n",
    "        }\n",
    "\n",
    "    def close(self):\n",
    "        for s in self.day_srcs:\n",
    "            s.close()\n",
    "        self.night_src.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3c750c16",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =========================\n",
    "# 3. æ¨¡å‹å®šä¹‰(æ”¹è¿›ç‰ˆ)\n",
    "# =========================\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "class SourceAdapter(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels):\n",
    "        super().__init__()\n",
    "        self.conv = nn.Conv2d(in_channels, out_channels, 1, bias=False)\n",
    "        self.bn = nn.BatchNorm2d(out_channels)\n",
    "        self.relu = nn.ReLU(inplace=True)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        return self.relu(self.bn(self.conv(x)))\n",
    "\n",
    "class ResidualBlock(nn.Module):\n",
    "    def __init__(self, channels):\n",
    "        super().__init__()\n",
    "        self.conv1 = nn.Conv2d(channels, channels, 3, padding=1, bias=False)\n",
    "        self.bn1 = nn.BatchNorm2d(channels)\n",
    "        self.conv2 = nn.Conv2d(channels, channels, 3, padding=1, bias=False)\n",
    "        self.bn2 = nn.BatchNorm2d(channels)\n",
    "        self.relu = nn.ReLU(inplace=True)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        identity = x\n",
    "        out = self.relu(self.bn1(self.conv1(x)))\n",
    "        out = self.bn2(self.conv2(out))\n",
    "        out = out + identity\n",
    "        out = self.relu(out)\n",
    "        return out\n",
    "\n",
    "class ConvStem(nn.Module):\n",
    "    def __init__(self, in_channels, base_channels=64, num_blocks=2):\n",
    "        super().__init__()\n",
    "        self.conv1 = nn.Conv2d(in_channels, base_channels, 3, padding=1, bias=False)\n",
    "        self.bn1 = nn.BatchNorm2d(base_channels)\n",
    "        self.relu = nn.ReLU(inplace=True)\n",
    "        \n",
    "        self.blocks = nn.Sequential(\n",
    "            *[ResidualBlock(base_channels) for _ in range(num_blocks)]\n",
    "        )\n",
    "        \n",
    "        self.conv2 = nn.Conv2d(base_channels, base_channels, 3, padding=1, bias=False)\n",
    "        self.bn2 = nn.BatchNorm2d(base_channels)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = self.relu(self.bn1(self.conv1(x)))\n",
    "        x = self.blocks(x)\n",
    "        x = self.relu(self.bn2(self.conv2(x)))\n",
    "        return x\n",
    "\n",
    "class CompositionHead(nn.Module):\n",
    "    def __init__(self, in_channels, n_comp=4):\n",
    "        super().__init__()\n",
    "        self.conv1 = nn.Conv2d(in_channels, in_channels, 3, padding=1, bias=False)\n",
    "        self.bn1 = nn.BatchNorm2d(in_channels)\n",
    "        self.relu = nn.ReLU(inplace=True)\n",
    "        self.dropout = nn.Dropout2d(0.1)\n",
    "        self.conv2 = nn.Conv2d(in_channels, n_comp, 1)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = self.relu(self.bn1(self.conv1(x)))\n",
    "        x = self.dropout(x)\n",
    "        alpha_raw = self.conv2(x)\n",
    "        alpha = F.softplus(alpha_raw) + 1.0  # ä¿è¯>0\n",
    "        return alpha\n",
    "\n",
    "def dirichlet_nll(y_true, alpha, eps=1e-7):\n",
    "    \"\"\"\n",
    "    y_true: (B, C) or (B, C, 1, 1)\n",
    "    alpha : (B, C, H, W)\n",
    "    æˆ‘ä»¬åªå–ä¸­å¿ƒåƒå…ƒæ¥åšloss\n",
    "    \"\"\"\n",
    "    if y_true.dim() == 2:\n",
    "        y_true = y_true.unsqueeze(-1).unsqueeze(-1)  # (B,C,1,1)\n",
    "    if alpha.dim() == 4:\n",
    "        B, C, H, W = alpha.shape\n",
    "        c = H // 2\n",
    "        alpha = alpha[:, :, c, c]  # (B, C)\n",
    "\n",
    "    alpha0 = alpha.sum(dim=1, keepdim=True)  # (B,1)\n",
    "    logC = torch.lgamma(alpha0) - torch.lgamma(alpha).sum(dim=1, keepdim=True)\n",
    "\n",
    "    y_safe = torch.clamp(y_true.squeeze(-1).squeeze(-1), min=eps, max=1.0-eps)\n",
    "    logL = logC + ((alpha - 1) * torch.log(y_safe)).sum(dim=1, keepdim=True)\n",
    "    return -logL.mean()\n",
    "\n",
    "class DayOnlyNet(nn.Module):\n",
    "    def __init__(self, day_channels=7, n_comp=4, shared_c=64):\n",
    "        super().__init__()\n",
    "        self.day_adapter = SourceAdapter(day_channels, shared_c)\n",
    "        self.backbone = ConvStem(in_channels=shared_c, base_channels=shared_c)\n",
    "        self.head = CompositionHead(in_channels=shared_c, n_comp=n_comp)\n",
    "    \n",
    "    def forward(self, day, night=None):\n",
    "        d = self.day_adapter(day)\n",
    "        x = self.backbone(d)\n",
    "        alpha = self.head(x)\n",
    "        return alpha\n",
    "\n",
    "class NightOnlyNet(nn.Module):\n",
    "    def __init__(self, night_channels=1, n_comp=4, shared_c=64):\n",
    "        super().__init__()\n",
    "        self.night_adapter = SourceAdapter(night_channels, shared_c)\n",
    "        self.backbone = ConvStem(in_channels=shared_c, base_channels=shared_c)\n",
    "        self.head = CompositionHead(in_channels=shared_c, n_comp=n_comp)\n",
    "    \n",
    "    def forward(self, day=None, night=None):\n",
    "        n = self.night_adapter(night)\n",
    "        x = self.backbone(n)\n",
    "        alpha = self.head(x)\n",
    "        return alpha\n",
    "\n",
    "class FusionNet(nn.Module):\n",
    "    def __init__(self, day_channels=7, night_channels=1, n_comp=4, shared_c=64):\n",
    "        super().__init__()\n",
    "        self.day_adapter = SourceAdapter(day_channels, shared_c)\n",
    "        self.night_adapter = SourceAdapter(night_channels, shared_c)\n",
    "        self.shared_backbone = ConvStem(in_channels=2*shared_c, base_channels=shared_c, num_blocks=3)\n",
    "        self.head = CompositionHead(in_channels=shared_c, n_comp=n_comp)\n",
    "    \n",
    "    def forward(self, day, night):\n",
    "        d = self.day_adapter(day)\n",
    "        n = self.night_adapter(night)\n",
    "        x = torch.cat([d, n], dim=1)\n",
    "        x = self.shared_backbone(x)\n",
    "        alpha = self.head(x)\n",
    "        return alpha\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2707c0d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =========================\n",
    "# 4. å•æŠ˜ + å•ä¸€æ•°æ®æ¯”ä¾‹è®­ç»ƒ(æ”¹è¿›ç‰ˆ)\n",
    "# =========================\n",
    "from sklearn.metrics import r2_score, mean_squared_error, mean_absolute_error\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm\n",
    "\n",
    "plt.rcParams[\"font.size\"] = 12\n",
    "plt.rcParams[\"font.weight\"] = \"normal\"\n",
    "\n",
    "def train_one_fold_one_fraction(full_ds,\n",
    "                                train_idx_full,\n",
    "                                val_idx,\n",
    "                                test_idx,\n",
    "                                model_kind=\"fusion\",\n",
    "                                data_fraction=1.0,\n",
    "                                fold_id=1):\n",
    "    \"\"\"\n",
    "    å•æŠ˜å•æ¯”ä¾‹è®­ç»ƒï¼Œå¹¶è¿”å›ä¸€ä¸ª metrics dict\n",
    "    \"\"\"\n",
    "    # 1) æŒ‰æ¯”ä¾‹è£è®­ç»ƒé›†\n",
    "    n_train_use = max(1, int(len(train_idx_full) * data_fraction))\n",
    "    train_idx = train_idx_full[:n_train_use]\n",
    "\n",
    "    train_subset = torch.utils.data.Subset(full_ds, list(train_idx))\n",
    "    val_subset = torch.utils.data.Subset(full_ds, list(val_idx))\n",
    "    test_subset = torch.utils.data.Subset(full_ds, list(test_idx))\n",
    "\n",
    "    train_loader = DataLoader(train_subset, batch_size=BATCH_SIZE, \n",
    "                            shuffle=True, num_workers=0, pin_memory=True)\n",
    "    val_loader = DataLoader(val_subset, batch_size=BATCH_SIZE, \n",
    "                          shuffle=False, num_workers=0, pin_memory=True)\n",
    "    test_loader = DataLoader(test_subset, batch_size=BATCH_SIZE, \n",
    "                           shuffle=False, num_workers=0, pin_memory=True)\n",
    "\n",
    "    # 2) é€‰æ¨¡å‹\n",
    "    if model_kind == \"day\":\n",
    "        model = DayOnlyNet(day_channels=len(DAY_TIFS), n_comp=len(TARGET_FIELDS)).to(DEVICE)\n",
    "    elif model_kind == \"night\":\n",
    "        model = NightOnlyNet(n_comp=len(TARGET_FIELDS)).to(DEVICE)\n",
    "    else:\n",
    "        model = FusionNet(day_channels=len(DAY_TIFS), night_channels=1, \n",
    "                         n_comp=len(TARGET_FIELDS)).to(DEVICE)\n",
    "\n",
    "    optimizer = torch.optim.AdamW(model.parameters(), lr=LEARNING_RATE, \n",
    "                                  weight_decay=WEIGHT_DECAY)\n",
    "\n",
    "    # â˜…â˜… è¿™é‡Œå»æ‰ verbose å‚æ•° â˜…â˜…\n",
    "    scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(\n",
    "        optimizer,\n",
    "        mode='min',\n",
    "        factor=0.5,\n",
    "        patience=5,\n",
    "        min_lr=1e-6,\n",
    "    )\n",
    "\n",
    "    best_val = 1e9\n",
    "    best_state = None\n",
    "    patience = 10\n",
    "    no_improve = 0\n",
    "\n",
    "    for epoch in range(EPOCHS):\n",
    "        # ----- è®­ç»ƒ -----\n",
    "        model.train()\n",
    "        train_loss = 0.0\n",
    "        for batch in train_loader:\n",
    "            day = batch[\"day\"].to(DEVICE, non_blocking=True)\n",
    "            night = batch[\"night\"].to(DEVICE, non_blocking=True)\n",
    "            y = batch[\"y\"].to(DEVICE, non_blocking=True)\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            if model_kind == \"day\":\n",
    "                alpha = model(day, None)\n",
    "            elif model_kind == \"night\":\n",
    "                alpha = model(None, night)\n",
    "            else:\n",
    "                alpha = model(day, night)\n",
    "\n",
    "            loss = dirichlet_nll(y, alpha)\n",
    "            loss.backward()\n",
    "            torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=1.0)\n",
    "            optimizer.step()\n",
    "            train_loss += loss.item() * day.size(0)\n",
    "\n",
    "        train_loss /= len(train_loader.dataset)\n",
    "\n",
    "        # ----- éªŒè¯ -----\n",
    "        model.eval()\n",
    "        val_loss = 0.0\n",
    "        y_true_all = []\n",
    "        y_pred_all = []\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            for batch in val_loader:\n",
    "                day = batch[\"day\"].to(DEVICE, non_blocking=True)\n",
    "                night = batch[\"night\"].to(DEVICE, non_blocking=True)\n",
    "                y = batch[\"y\"].to(DEVICE, non_blocking=True)\n",
    "\n",
    "                if model_kind == \"day\":\n",
    "                    alpha = model(day, None)\n",
    "                elif model_kind == \"night\":\n",
    "                    alpha = model(None, night)\n",
    "                else:\n",
    "                    alpha = model(day, night)\n",
    "\n",
    "                loss = dirichlet_nll(y, alpha)\n",
    "                val_loss += loss.item() * day.size(0)\n",
    "\n",
    "                H = alpha.shape[2]\n",
    "                c = H // 2\n",
    "                alpha_c = alpha[:, :, c, c]\n",
    "                \n",
    "                alpha_np = alpha_c.cpu().numpy()\n",
    "                y_np = y.cpu().numpy()\n",
    "                pred_np = alpha_np / np.clip(alpha_np.sum(axis=1, keepdims=True), 1e-6, None)\n",
    "                \n",
    "                y_true_all.append(y_np)\n",
    "                y_pred_all.append(pred_np)\n",
    "\n",
    "        val_loss /= len(val_loader.dataset)\n",
    "        y_true_all = np.vstack(y_true_all)\n",
    "        y_pred_all = np.vstack(y_pred_all)\n",
    "\n",
    "        valid_mask = np.isfinite(y_true_all).all(axis=1) & np.isfinite(y_pred_all).all(axis=1)\n",
    "        y_true_all = y_true_all[valid_mask]\n",
    "        y_pred_all = y_pred_all[valid_mask]\n",
    "\n",
    "        if y_true_all.shape[0] < 2:\n",
    "            r2_mean = float(\"nan\")\n",
    "        else:\n",
    "            y_true_all = np.clip(y_true_all, 0.0, 1.0)\n",
    "            y_pred_all = np.clip(y_pred_all, 0.0, 1.0)\n",
    "            r2_each = [r2_score(y_true_all[:, i], y_pred_all[:, i]) \n",
    "                      for i in range(len(TARGET_FIELDS))]\n",
    "            r2_mean = float(np.mean(r2_each))\n",
    "\n",
    "        if epoch % 10 == 0 or epoch == EPOCHS - 1:\n",
    "            print(f\"[Fold {fold_id}][frac {data_fraction:.2f}] \"\n",
    "                  f\"epoch {epoch+1}/{EPOCHS} \"\n",
    "                  f\"train_loss={train_loss:.4f} val_loss={val_loss:.4f} meanRÂ²={r2_mean:.3f}\")\n",
    "\n",
    "        scheduler.step(val_loss)\n",
    "\n",
    "        # æ—©åœ\n",
    "        if val_loss < best_val - 1e-5:\n",
    "            best_val = val_loss\n",
    "            best_state = model.state_dict()\n",
    "            no_improve = 0\n",
    "        else:\n",
    "            no_improve += 1\n",
    "            if no_improve >= patience:\n",
    "                print(f\"Early stopping at epoch {epoch+1}\")\n",
    "                break\n",
    "\n",
    "    # ---- æµ‹è¯•é›†è¯„ä¼° ----\n",
    "    if best_state is not None:\n",
    "        model.load_state_dict(best_state)\n",
    "    \n",
    "    model.eval()\n",
    "    y_true_all = []\n",
    "    y_pred_all = []\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for batch in test_loader:\n",
    "            day = batch[\"day\"].to(DEVICE, non_blocking=True)\n",
    "            night = batch[\"night\"].to(DEVICE, non_blocking=True)\n",
    "            y = batch[\"y\"].to(DEVICE, non_blocking=True)\n",
    "\n",
    "            if model_kind == \"day\":\n",
    "                alpha = model(day, None)\n",
    "            elif model_kind == \"night\":\n",
    "                alpha = model(None, night)\n",
    "            else:\n",
    "                alpha = model(day, night)\n",
    "\n",
    "            H = alpha.shape[2]\n",
    "            c = H // 2\n",
    "            alpha_c = alpha[:, :, c, c]\n",
    "\n",
    "            alpha_np = alpha_c.cpu().numpy()\n",
    "            y_np = y.cpu().numpy()\n",
    "            pred_np = alpha_np / np.clip(alpha_np.sum(axis=1, keepdims=True), 1e-6, None)\n",
    "            \n",
    "            y_true_all.append(y_np)\n",
    "            y_pred_all.append(pred_np)\n",
    "\n",
    "    y_true_all = np.vstack(y_true_all)\n",
    "    y_pred_all = np.vstack(y_pred_all)\n",
    "    \n",
    "    valid_mask = np.isfinite(y_true_all).all(axis=1) & np.isfinite(y_pred_all).all(axis=1)\n",
    "    y_true_all = y_true_all[valid_mask]\n",
    "    y_pred_all = y_pred_all[valid_mask]\n",
    "\n",
    "    if y_true_all.shape[0] < 2:\n",
    "        test_r2_mean = float(\"nan\")\n",
    "        test_r2_each = [float(\"nan\")] * len(TARGET_FIELDS)\n",
    "        test_rmse_each = [float(\"nan\")] * len(TARGET_FIELDS)\n",
    "        test_mae_each = [float(\"nan\")] * len(TARGET_FIELDS)\n",
    "    else:\n",
    "        y_true_all = np.clip(y_true_all, 0.0, 1.0)\n",
    "        y_pred_all = np.clip(y_pred_all, 0.0, 1.0)\n",
    "        \n",
    "        test_r2_each = [r2_score(y_true_all[:, i], y_pred_all[:, i]) \n",
    "                       for i in range(len(TARGET_FIELDS))]\n",
    "        test_rmse_each = [np.sqrt(mean_squared_error(y_true_all[:, i], y_pred_all[:, i])) \n",
    "                         for i in range(len(TARGET_FIELDS))]\n",
    "        test_mae_each = [mean_absolute_error(y_true_all[:, i], y_pred_all[:, i]) \n",
    "                        for i in range(len(TARGET_FIELDS))]\n",
    "        test_r2_mean = float(np.mean(test_r2_each))\n",
    "\n",
    "    metrics = {\n",
    "        \"fold\": fold_id,\n",
    "        \"fraction\": data_fraction,\n",
    "        \"model\": model_kind,\n",
    "        \"val_loss\": best_val,\n",
    "        \"test_r2_mean\": test_r2_mean,\n",
    "        \"n_train\": len(train_idx),\n",
    "        \"n_val\": len(val_idx),\n",
    "        \"n_test\": len(test_idx),\n",
    "    }\n",
    "    \n",
    "    for i, name in enumerate(TARGET_FIELDS):\n",
    "        metrics[f\"test_r2_{name}\"] = test_r2_each[i] if i < len(test_r2_each) else float(\"nan\")\n",
    "        metrics[f\"test_rmse_{name}\"] = test_rmse_each[i] if i < len(test_rmse_each) else float(\"nan\")\n",
    "        metrics[f\"test_mae_{name}\"] = test_mae_each[i] if i < len(test_mae_each) else float(\"nan\")\n",
    "\n",
    "    # ä¿å­˜æœ€ä½³æ¨¡å‹ï¼ˆåªä¿å­˜å…¨é‡ï¼‰\n",
    "    if data_fraction >= 0.99:\n",
    "        model_path = os.path.join(OUT_DIR, f\"{model_kind}_fold{fold_id}_best.pth\")\n",
    "        torch.save(best_state, model_path)\n",
    "        print(f\"âœ… æ¨¡å‹å·²ä¿å­˜: {model_path}\")\n",
    "\n",
    "    return metrics\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "cc451724",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =========================\n",
    "# 5. 5æŠ˜ Ã— å¤šæ¯”ä¾‹ æ€»æ§(æ”¹è¿›ç‰ˆ)\n",
    "# =========================\n",
    "from sklearn.model_selection import KFold\n",
    "\n",
    "def run_5fold_with_fractions():\n",
    "    print(\"=\" * 60)\n",
    "    print(\"å¼€å§‹æ„å»ºæ•°æ®é›†...\")\n",
    "    print(\"=\" * 60)\n",
    "    \n",
    "    full_ds = PatchPointDataset(\n",
    "        LABEL_SHP,\n",
    "        DAY_TIFS,\n",
    "        NIGHT_TIF,\n",
    "        TARGET_FIELDS,\n",
    "        patch=PATCH_SIZE,\n",
    "        augment=True\n",
    "    )\n",
    "    \n",
    "    n_total = len(full_ds)\n",
    "    all_idx = np.arange(n_total)\n",
    "\n",
    "    model_list = []\n",
    "    if RUN_DAY:\n",
    "        model_list.append(\"day\")\n",
    "    if RUN_NIGHT:\n",
    "        model_list.append(\"night\")\n",
    "    if RUN_FUSION:\n",
    "        model_list.append(\"fusion\")\n",
    "\n",
    "    kf = KFold(n_splits=5, shuffle=True, random_state=42)\n",
    "    all_results = []\n",
    "\n",
    "    fold_id = 0\n",
    "    for trainval_idx, test_idx in kf.split(all_idx):\n",
    "        fold_id += 1\n",
    "\n",
    "        np.random.seed(fold_id)\n",
    "        np.random.shuffle(trainval_idx)\n",
    "        n_val = max(1, int(len(trainval_idx) * 0.2))\n",
    "        val_idx = trainval_idx[:n_val]\n",
    "        train_idx_full = trainval_idx[n_val:]\n",
    "\n",
    "        print(f\"\\n{'='*60}\")\n",
    "        print(f\"Fold {fold_id}/5\")\n",
    "        print(f\"{'='*60}\")\n",
    "        print(f\"Train_full={len(train_idx_full)}, Val={len(val_idx)}, Test={len(test_idx)}\")\n",
    "\n",
    "        for mk in model_list:\n",
    "            for frac in FRACTIONS:\n",
    "                try:\n",
    "                    print(f\"\\n--- Fold {fold_id}, Model={mk}, Fraction={frac*100:.0f}% ---\")\n",
    "                    m = train_one_fold_one_fraction(\n",
    "                        full_ds,\n",
    "                        train_idx_full=train_idx_full,\n",
    "                        val_idx=val_idx,\n",
    "                        test_idx=test_idx,\n",
    "                        model_kind=mk,\n",
    "                        data_fraction=frac,\n",
    "                        fold_id=fold_id\n",
    "                    )\n",
    "                    all_results.append(m)\n",
    "                    \n",
    "                    # å®æ—¶ä¿å­˜\n",
    "                    df_temp = pd.DataFrame(all_results)\n",
    "                    temp_csv = os.path.join(OUT_DIR, \"cv5_temp_results.csv\")\n",
    "                    df_temp.to_csv(temp_csv, index=False)\n",
    "                    \n",
    "                except Exception as e:\n",
    "                    print(f\"âŒ Error in fold {fold_id}, model {mk}, frac {frac}: {e}\")\n",
    "                    import traceback\n",
    "                    traceback.print_exc()\n",
    "                    # æŠŠé”™è¯¯ä¹Ÿè®°å½•è¿›å»ï¼Œé˜²æ­¢æœ€åæ˜¯ç©ºè¡¨\n",
    "                    all_results.append({\n",
    "                        \"fold\": fold_id,\n",
    "                        \"fraction\": frac,\n",
    "                        \"model\": mk,\n",
    "                        \"error\": str(e)\n",
    "                    })\n",
    "                    df_temp = pd.DataFrame(all_results)\n",
    "                    temp_csv = os.path.join(OUT_DIR, \"cv5_temp_results.csv\")\n",
    "                    df_temp.to_csv(temp_csv, index=False)\n",
    "                    continue\n",
    "\n",
    "    df = pd.DataFrame(all_results)\n",
    "    csv_path = os.path.join(OUT_DIR, \"cv5_all_fractions_results.csv\")\n",
    "    df.to_csv(csv_path, index=False)\n",
    "    \n",
    "    print(f\"\\n{'='*60}\")\n",
    "    print(\"âœ… 5æŠ˜Ã—å¤šæ¯”ä¾‹ å®éªŒç»“æœå·²ä¿å­˜:\", csv_path)\n",
    "    print(f\"{'='*60}\")\n",
    "    \n",
    "    print(\"\\nğŸ“Š ç»“æœæ±‡æ€»:\")\n",
    "    for mk in model_list:\n",
    "        for frac in FRACTIONS:\n",
    "            sub = df[(df[\"model\"] == mk) & (df[\"fraction\"] == frac)]\n",
    "            if not sub.empty and \"test_r2_mean\" in sub.columns:\n",
    "                mean_r2 = sub[\"test_r2_mean\"].mean()\n",
    "                std_r2 = sub[\"test_r2_mean\"].std()\n",
    "                print(f\"{mk} @ {frac*100:.0f}%: RÂ² = {mean_r2:.3f} Â± {std_r2:.3f}\")\n",
    "    \n",
    "    full_ds.close()\n",
    "    \n",
    "    return df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f0c6b974",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =========================\n",
    "# 6. å…¨å¹…å½±åƒæ¨ç†(æ”¹è¿›ç‰ˆ)\n",
    "# =========================\n",
    "import math\n",
    "from tqdm import tqdm\n",
    "\n",
    "def infer_full_raster(\n",
    "    model_path,\n",
    "    out_dir=OUT_DIR,\n",
    "    patch_size=PATCH_SIZE,\n",
    "    step=None,\n",
    "    batch_size=16,\n",
    "    tag=None,\n",
    "):\n",
    "    os.makedirs(out_dir, exist_ok=True)\n",
    "\n",
    "    day_srcs = [rasterio.open(p) for p in DAY_TIFS]\n",
    "    night_src = rasterio.open(NIGHT_TIF)\n",
    "\n",
    "    base_meta = day_srcs[0].meta.copy()\n",
    "    height = day_srcs[0].height\n",
    "    width = day_srcs[0].width\n",
    "\n",
    "    print(f\"å½±åƒå°ºå¯¸: {height} Ã— {width}\")\n",
    "\n",
    "    model = FusionNet(\n",
    "        day_channels=len(DAY_TIFS),\n",
    "        night_channels=1,\n",
    "        n_comp=len(TARGET_FIELDS)\n",
    "    ).to(DEVICE)\n",
    "    \n",
    "    try:\n",
    "        state_dict = torch.load(model_path, map_location=DEVICE)\n",
    "        model.load_state_dict(state_dict)\n",
    "        print(f\"âœ… æ¨¡å‹åŠ è½½æˆåŠŸ: {model_path}\")\n",
    "    except Exception as e:\n",
    "        print(f\"âŒ æ¨¡å‹åŠ è½½å¤±è´¥: {e}\")\n",
    "        return\n",
    "    \n",
    "    model.eval()\n",
    "\n",
    "    out_paths = []\n",
    "    out_files = []\n",
    "    base_meta.update({\n",
    "        \"count\": 1,\n",
    "        \"dtype\": \"float32\",\n",
    "        \"compress\": \"lzw\",\n",
    "        \"nodata\": -9999\n",
    "    })\n",
    "    \n",
    "    for name in TARGET_FIELDS:\n",
    "        if tag:\n",
    "            fname = f\"pred_{tag}_{name}_2020_90m.tif\"\n",
    "        else:\n",
    "            fname = f\"pred_{name}_2020_90m.tif\"\n",
    "        op = os.path.join(out_dir, fname)\n",
    "        out_paths.append(op)\n",
    "        out_files.append(rasterio.open(op, \"w\", **base_meta))\n",
    "\n",
    "    ps = patch_size\n",
    "    if step is None:\n",
    "        step = patch_size // 2\n",
    "\n",
    "    windows = []\n",
    "    for row in range(0, height, step):\n",
    "        for col in range(0, width, step):\n",
    "            win_h = min(ps, height - row)\n",
    "            win_w = min(ps, width - col)\n",
    "            windows.append((row, col, win_h, win_w))\n",
    "\n",
    "    print(f\"ğŸ—ºï¸ å¼€å§‹å…¨å¹…æ¨ç† (å…± {len(windows)} ä¸ªçª—å£)...\")\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for i in tqdm(range(0, len(windows), batch_size), desc=\"æ¨ç†è¿›åº¦\"):\n",
    "            batch_windows = windows[i:i+batch_size]\n",
    "            batch_day = []\n",
    "            batch_night = []\n",
    "            valid_flags = []\n",
    "            \n",
    "            for row, col, win_h, win_w in batch_windows:\n",
    "                window = rasterio.windows.Window(col, row, win_w, win_h)\n",
    "                \n",
    "                day_stack = []\n",
    "                all_valid = True\n",
    "                for src in day_srcs:\n",
    "                    arr = src.read(1, window=window, boundless=True, masked=True)\n",
    "                    if arr.mask.all():\n",
    "                        all_valid = False\n",
    "                        break\n",
    "                    day_stack.append(arr.filled(0).astype(np.float32))\n",
    "                \n",
    "                night_arr = night_src.read(1, window=window, boundless=True, masked=True)\n",
    "                if night_arr.mask.all():\n",
    "                    all_valid = False\n",
    "                \n",
    "                valid_flags.append(all_valid)\n",
    "                \n",
    "                if not all_valid:\n",
    "                    batch_day.append(None)\n",
    "                    batch_night.append(None)\n",
    "                    continue\n",
    "                \n",
    "                day_arr = np.stack(day_stack, axis=0)\n",
    "                night_arr = np.expand_dims(night_arr.filled(0).astype(np.float32), axis=0)\n",
    "                \n",
    "                if win_h != ps or win_w != ps:\n",
    "                    pad_day = np.zeros((day_arr.shape[0], ps, ps), dtype=np.float32)\n",
    "                    pad_night = np.zeros((1, ps, ps), dtype=np.float32)\n",
    "                    pad_day[:, :win_h, :win_w] = day_arr\n",
    "                    pad_night[:, :win_h, :win_w] = night_arr\n",
    "                    day_arr = pad_day\n",
    "                    night_arr = pad_night\n",
    "                \n",
    "                batch_day.append(day_arr)\n",
    "                batch_night.append(night_arr)\n",
    "            \n",
    "            for idx, (all_valid, (row, col, win_h, win_w)) in enumerate(zip(valid_flags, batch_windows)):\n",
    "                window = rasterio.windows.Window(col, row, win_w, win_h)\n",
    "                \n",
    "                if not all_valid:\n",
    "                    for o in out_files:\n",
    "                        o.write(np.full((win_h, win_w), -9999, dtype=np.float32), 1, window=window)\n",
    "                    continue\n",
    "                \n",
    "                day_t = torch.from_numpy(batch_day[idx]).unsqueeze(0).to(DEVICE)\n",
    "                night_t = torch.from_numpy(batch_night[idx]).unsqueeze(0).to(DEVICE)\n",
    "                \n",
    "                alpha = model(day_t, night_t)\n",
    "                alpha = alpha.squeeze(0).cpu().numpy()\n",
    "                \n",
    "                denom = np.clip(alpha.sum(axis=0, keepdims=True), 1e-6, None)\n",
    "                comp = alpha / denom\n",
    "                \n",
    "                for comp_idx, o in enumerate(out_files):\n",
    "                    o.write(comp[comp_idx, :win_h, :win_w].astype(np.float32), 1, window=window)\n",
    "\n",
    "    for src in day_srcs:\n",
    "        src.close()\n",
    "    night_src.close()\n",
    "    for o in out_files:\n",
    "        o.close()\n",
    "\n",
    "    print(\"âœ… æ¨ç†å®Œæˆ,è¾“å‡ºåˆ°:\")\n",
    "    for p in out_paths:\n",
    "        print(f\"  - {p}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "81e96707",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =========================\n",
    "# 7. å¯è§†åŒ–è¯„ä¼°ç»“æœ(æ”¹è¿›ç‰ˆï¼Œå®Œæ•´ç‰ˆ)\n",
    "# =========================\n",
    "def plot_from_cv_results(\n",
    "    csv_path=os.path.join(OUT_DIR, \"cv5_all_fractions_results.csv\"),\n",
    "    out_dir=OUT_DIR\n",
    "):\n",
    "    \"\"\"\n",
    "    ä»äº¤å‰éªŒè¯ç»“æœcsvç”Ÿæˆå¤šç§å›¾ï¼š\n",
    "    1) å„æ¨¡å‹ï¼šè®­ç»ƒæ¯”ä¾‹ vs å¹³å‡RÂ² æŠ˜çº¿å›¾\n",
    "    2) å•æ¨¡å‹(100%æ•°æ®)ï¼šå››ä¸ªç»„æˆå˜é‡çš„RÂ²ç®±çº¿å›¾\n",
    "    3) å¤šæ¨¡å‹ï¼šå¯¹æ¯”æŠ˜çº¿å›¾\n",
    "    4) å•æ¨¡å‹(100%æ•°æ®)ï¼šå„æŠ˜Ã—å„å˜é‡çš„RÂ²çƒ­åŠ›å›¾\n",
    "    \"\"\"\n",
    "    import pandas as pd\n",
    "    import matplotlib.pyplot as plt\n",
    "\n",
    "    # å¯é€‰çš„ seabornï¼Œç¾åŒ–å›¾å½¢ï¼›æ²¡æœ‰ä¹Ÿèƒ½è·‘\n",
    "    try:\n",
    "        import seaborn as sns\n",
    "        sns.set_palette(\"husl\")\n",
    "        use_sns = True\n",
    "    except ImportError:\n",
    "        use_sns = False\n",
    "\n",
    "    if not os.path.exists(csv_path):\n",
    "        print(f\"âš ï¸ æ‰¾ä¸åˆ°ç»“æœæ–‡ä»¶: {csv_path}\")\n",
    "        return\n",
    "\n",
    "    df = pd.read_csv(csv_path)\n",
    "    if df.empty or \"model\" not in df.columns:\n",
    "        print(\"âš ï¸ ç»“æœè¡¨ä¸ºç©ºï¼Œæˆ–è€…ç¼ºå°‘ 'model' åˆ—ï¼Œæ— æ³•ç»˜å›¾ã€‚\")\n",
    "        return\n",
    "\n",
    "    os.makedirs(out_dir, exist_ok=True)\n",
    "\n",
    "    models = df[\"model\"].dropna().unique()\n",
    "\n",
    "    # ========= å›¾1: æ•°æ®æ¯”ä¾‹ vs RÂ² =========\n",
    "    fig, axes = plt.subplots(1, len(models), figsize=(6 * len(models), 5))\n",
    "    if len(models) == 1:\n",
    "        axes = [axes]\n",
    "\n",
    "    for idx, mk in enumerate(models):\n",
    "        sub = df[(df[\"model\"] == mk) & (df[\"fraction\"].notna())]\n",
    "\n",
    "        # åªå¯¹æœ‰ test_r2_mean çš„åšèšåˆ\n",
    "        sub = sub[sub[\"test_r2_mean\"].notna()]\n",
    "\n",
    "        g = sub.groupby(\"fraction\")[\"test_r2_mean\"].agg([\"mean\", \"std\", \"count\"]).reset_index()\n",
    "\n",
    "        ax = axes[idx]\n",
    "        ax.errorbar(\n",
    "            g[\"fraction\"] * 100,\n",
    "            g[\"mean\"],\n",
    "            yerr=g[\"std\"].fillna(0),\n",
    "            fmt=\"-o\",\n",
    "            linewidth=2.2,\n",
    "            markersize=7,\n",
    "            capsize=5,\n",
    "            capthick=1.5,\n",
    "        )\n",
    "        ax.set_xlabel(\"Percent of training data used (%)\", fontsize=12, fontweight=\"bold\")\n",
    "        ax.set_ylabel(\"Held-out mean RÂ²\", fontsize=12, fontweight=\"bold\")\n",
    "        ax.set_title(f\"Performance vs Data Fraction ({mk.upper()})\", fontsize=13, fontweight=\"bold\")\n",
    "        ax.grid(True, alpha=0.3)\n",
    "\n",
    "        # é€‚å½“è®¾ç½® y èŒƒå›´\n",
    "        y_min = (g[\"mean\"] - g[\"std\"].fillna(0)).min()\n",
    "        y_max = (g[\"mean\"] + g[\"std\"].fillna(0)).max()\n",
    "        ax.set_ylim([max(-0.1, y_min - 0.05), min(1.05, y_max + 0.05)])\n",
    "\n",
    "    plt.tight_layout()\n",
    "    out_png = os.path.join(out_dir, \"fig_fraction_vs_r2_all_models.png\")\n",
    "    plt.savefig(out_png, dpi=300, bbox_inches=\"tight\")\n",
    "    plt.close()\n",
    "    print(f\"ğŸ“ˆ å·²è¾“å‡º: {out_png}\")\n",
    "\n",
    "    # ========= å›¾2: æ¯ä¸ªæ¨¡å‹åœ¨100%æ•°æ®ä¸‹ï¼Œå„å˜é‡çš„RÂ²ç®±çº¿å›¾ =========\n",
    "    # æˆ‘ä»¬åªç”» fraction >= 0.999 çš„ï¼Œä¹Ÿå°±æ˜¯å…¨é‡æ•°æ®\n",
    "    for mk in models:\n",
    "        sub = df[(df[\"model\"] == mk) & (df[\"fraction\"] >= 0.999)]\n",
    "        if sub.empty:\n",
    "            continue\n",
    "\n",
    "        # æ‰¾å‡ºæ‰€æœ‰ test_r2_ å‰ç¼€çš„åˆ—\n",
    "        r2_cols = [c for c in sub.columns if c.startswith(\"test_r2_\") and c != \"test_r2_mean\"]\n",
    "        if not r2_cols:\n",
    "            continue\n",
    "\n",
    "        data = []\n",
    "        labels = []\n",
    "        for col in r2_cols:\n",
    "            var_name = col.replace(\"test_r2_\", \"\")\n",
    "            data.append(sub[col].values)\n",
    "            labels.append(var_name)\n",
    "\n",
    "        fig, ax = plt.subplots(figsize=(10, 6))\n",
    "        bp = ax.boxplot(\n",
    "            data,\n",
    "            labels=labels,\n",
    "            patch_artist=True,\n",
    "            notch=True,\n",
    "            showmeans=True,\n",
    "        )\n",
    "\n",
    "        if use_sns:\n",
    "            palette = sns.color_palette(\"husl\", len(labels))\n",
    "        else:\n",
    "            # å…œåº•ç®€å•é¢œè‰²\n",
    "            palette = [(0.6, 0.8, 1.0)] * len(labels)\n",
    "\n",
    "        for patch, color in zip(bp[\"boxes\"], palette):\n",
    "            patch.set_facecolor(color)\n",
    "            patch.set_alpha(0.7)\n",
    "\n",
    "        ax.set_ylabel(\"RÂ² Score\", fontsize=12, fontweight=\"bold\")\n",
    "        ax.set_xlabel(\"Land Cover Component\", fontsize=12, fontweight=\"bold\")\n",
    "        ax.set_title(\n",
    "            f\"Per-Variable RÂ² Distribution ({mk.upper()}, 100% data)\",\n",
    "            fontsize=13,\n",
    "            fontweight=\"bold\",\n",
    "        )\n",
    "        ax.grid(True, axis=\"y\", alpha=0.3)\n",
    "\n",
    "        plt.tight_layout()\n",
    "        out_png = os.path.join(out_dir, f\"fig_per_variable_box_{mk}.png\")\n",
    "        plt.savefig(out_png, dpi=300, bbox_inches=\"tight\")\n",
    "        plt.close()\n",
    "        print(f\"ğŸ“¦ å·²è¾“å‡º: {out_png}\")\n",
    "\n",
    "    # ========= å›¾3: å¤šæ¨¡å‹å¯¹æ¯”ï¼ˆå¦‚æœä½ ä¸€æ¬¡è·‘äº† day/night/fusion å°±èƒ½çœ‹å‡ºæ¥ï¼‰ =========\n",
    "    if len(models) > 1:\n",
    "        fig, ax = plt.subplots(figsize=(11, 6))\n",
    "        for mk in models:\n",
    "            sub = df[(df[\"model\"] == mk) & (df[\"fraction\"].notna())]\n",
    "            sub = sub[sub[\"test_r2_mean\"].notna()]\n",
    "            g = sub.groupby(\"fraction\")[\"test_r2_mean\"].agg([\"mean\", \"std\"]).reset_index()\n",
    "            ax.errorbar(\n",
    "                g[\"fraction\"] * 100,\n",
    "                g[\"mean\"],\n",
    "                yerr=g[\"std\"].fillna(0),\n",
    "                fmt=\"-o\",\n",
    "                linewidth=2.2,\n",
    "                markersize=7,\n",
    "                capsize=4,\n",
    "                label=mk.upper(),\n",
    "            )\n",
    "\n",
    "        ax.set_xlabel(\"Percent of training data used (%)\", fontsize=12, fontweight=\"bold\")\n",
    "        ax.set_ylabel(\"Held-out mean RÂ²\", fontsize=12, fontweight=\"bold\")\n",
    "        ax.set_title(\"Model Comparison\", fontsize=14, fontweight=\"bold\")\n",
    "        ax.legend(fontsize=11, frameon=True, shadow=True)\n",
    "        ax.grid(True, alpha=0.3)\n",
    "\n",
    "        plt.tight_layout()\n",
    "        out_png = os.path.join(out_dir, \"fig_model_comparison.png\")\n",
    "        plt.savefig(out_png, dpi=300, bbox_inches=\"tight\")\n",
    "        plt.close()\n",
    "        print(f\"ğŸ”„ å·²è¾“å‡º: {out_png}\")\n",
    "\n",
    "    # ========= å›¾4: çƒ­åŠ›å›¾ - å„å˜é‡åœ¨ä¸åŒæŠ˜çš„è¡¨ç°(åªçœ‹100%æ•°æ®) =========\n",
    "    # è¿™é‡Œç”¨ seaborn ä¼šæ›´å¥½çœ‹ï¼Œæ²¡æœ‰ seaborn å°±ç”¨ matplotlib ç®€å•ç”»\n",
    "    for mk in models:\n",
    "        sub = df[(df[\"model\"] == mk) & (df[\"fraction\"] >= 0.999)]\n",
    "        if sub.empty:\n",
    "            continue\n",
    "\n",
    "        r2_cols = [c for c in sub.columns if c.startswith(\"test_r2_\") and c != \"test_r2_mean\"]\n",
    "        if not r2_cols:\n",
    "            continue\n",
    "\n",
    "        # æ„é€ æˆ (å˜é‡ Ã— æŠ˜) çš„è¡¨\n",
    "        heatmap_data = sub[[\"fold\"] + r2_cols].set_index(\"fold\")\n",
    "        heatmap_data.columns = [c.replace(\"test_r2_\", \"\") for c in heatmap_data.columns]\n",
    "\n",
    "        if use_sns:\n",
    "            import seaborn as sns\n",
    "            fig, ax = plt.subplots(figsize=(10, 6))\n",
    "            sns.heatmap(\n",
    "                heatmap_data.T,\n",
    "                annot=True,\n",
    "                fmt=\".3f\",\n",
    "                cmap=\"YlGnBu\",\n",
    "                cbar_kws={\"label\": \"RÂ² Score\"},\n",
    "                ax=ax,\n",
    "                vmin=0.0,\n",
    "                vmax=1.0,\n",
    "            )\n",
    "            ax.set_xlabel(\"Fold\", fontsize=12, fontweight=\"bold\")\n",
    "            ax.set_ylabel(\"Variable\", fontsize=12, fontweight=\"bold\")\n",
    "            ax.set_title(\n",
    "                f\"RÂ² Heatmap Across Folds ({mk.upper()}, 100% data)\",\n",
    "                fontsize=13,\n",
    "                fontweight=\"bold\",\n",
    "            )\n",
    "            plt.tight_layout()\n",
    "            out_png = os.path.join(out_dir, f\"fig_r2_heatmap_{mk}.png\")\n",
    "            plt.savefig(out_png, dpi=300, bbox_inches=\"tight\")\n",
    "            plt.close()\n",
    "            print(f\"ğŸ”¥ å·²è¾“å‡º: {out_png}\")\n",
    "        else:\n",
    "            # æ²¡æœ‰ seaborn çš„ç®€æ˜“ç‰ˆ\n",
    "            fig, ax = plt.subplots(figsize=(10, 6))\n",
    "            im = ax.imshow(heatmap_data.T, aspect=\"auto\", vmin=0.0, vmax=1.0, cmap=\"YlGnBu\")\n",
    "            ax.set_xticks(range(len(heatmap_data.index)))\n",
    "            ax.set_xticklabels(heatmap_data.index)\n",
    "            ax.set_yticks(range(len(heatmap_data.columns)))\n",
    "            ax.set_yticklabels(heatmap_data.columns)\n",
    "            ax.set_xlabel(\"Fold\")\n",
    "            ax.set_ylabel(\"Variable\")\n",
    "            ax.set_title(f\"RÂ² Heatmap Across Folds ({mk.upper()}, 100% data)\")\n",
    "            fig.colorbar(im, ax=ax, label=\"RÂ² Score\")\n",
    "            plt.tight_layout()\n",
    "            out_png = os.path.join(out_dir, f\"fig_r2_heatmap_{mk}.png\")\n",
    "            plt.savefig(out_png, dpi=300, bbox_inches=\"tight\")\n",
    "            plt.close()\n",
    "            print(f\"ğŸ”¥ å·²è¾“å‡º(ç®€æ˜“ç‰ˆ): {out_png}\")\n",
    "\n",
    "    print(\"\\nâœ… æ‰€æœ‰å›¾è¡¨ç”Ÿæˆå®Œæˆ!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95cd15d2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "======================================================================\n",
      " Landsat + å¤œå…‰æ•°æ®æ·±åº¦å­¦ä¹ ç»„æˆé¢„æµ‹ç³»ç»Ÿ\n",
      "======================================================================\n",
      "\n",
      "ğŸ“Š æ­¥éª¤1: è¿è¡Œ5æŠ˜äº¤å‰éªŒè¯å®éªŒ...\n",
      "============================================================\n",
      "å¼€å§‹æ„å»ºæ•°æ®é›†...\n",
      "============================================================\n",
      "â³ æ­£åœ¨æ£€æŸ¥å“ªäº›æ ·æœ¬åœ¨å½±åƒä¸Šæœ‰å€¼...\n",
      "âœ… å¯ç”¨æ ·æœ¬æ•°: 38499 / 38577\n",
      "\n",
      "============================================================\n",
      "Fold 1/5\n",
      "============================================================\n",
      "Train_full=24640, Val=6159, Test=7700\n",
      "\n",
      "--- Fold 1, Model=fusion, Fraction=5% ---\n",
      "[Fold 1][frac 0.05] epoch 1/100 train_loss=-1.5385 val_loss=-0.1998 meanRÂ²=-0.250\n"
     ]
    }
   ],
   "source": [
    "# =========================\n",
    "# 8. ä¸»å‡½æ•°\n",
    "# =========================\n",
    "if __name__ == \"__main__\":\n",
    "    print(\"=\"*70)\n",
    "    print(\" Landsat + å¤œå…‰æ•°æ®æ·±åº¦å­¦ä¹ ç»„æˆé¢„æµ‹ç³»ç»Ÿ\")\n",
    "    print(\"=\"*70)\n",
    "    \n",
    "    # æ­¥éª¤1: è¿è¡Œ5æŠ˜äº¤å‰éªŒè¯\n",
    "    print(\"\\nğŸ“Š æ­¥éª¤1: è¿è¡Œ5æŠ˜äº¤å‰éªŒè¯å®éªŒ...\")\n",
    "    try:\n",
    "        df_results = run_5fold_with_fractions()\n",
    "    except Exception as e:\n",
    "        print(f\"âŒ äº¤å‰éªŒè¯å¤±è´¥: {e}\")\n",
    "        import traceback\n",
    "        traceback.print_exc()\n",
    "        df_results = None\n",
    "    \n",
    "    # æ­¥éª¤2: ç”Ÿæˆè¯„ä¼°å›¾è¡¨\n",
    "    if df_results is not None:\n",
    "        print(\"\\nğŸ“ˆ æ­¥éª¤2: ç”Ÿæˆè¯„ä¼°å›¾è¡¨...\")\n",
    "        try:\n",
    "            plot_from_cv_results()\n",
    "        except Exception as e:\n",
    "            print(f\"âŒ å›¾è¡¨ç”Ÿæˆå¤±è´¥: {e}\")\n",
    "            import traceback\n",
    "            traceback.print_exc()\n",
    "    \n",
    "    # æ­¥éª¤3: è‡ªåŠ¨é€‰æ‹© RÂ² æœ€é«˜çš„èåˆæ¨¡å‹è¿›è¡Œå…¨å¹…å½±åƒæ¨ç†\n",
    "    print(\"\\nğŸ—ºï¸ æ­¥éª¤3: æ ¹æ®æœ€ä½³ RÂ² è‡ªåŠ¨é€‰æ‹©æ¨¡å‹å¹¶åˆ¶å›¾...\")\n",
    "    try:\n",
    "        import pandas as pd\n",
    "\n",
    "        csv_path = os.path.join(OUT_DIR, \"cv5_all_fractions_results.csv\")\n",
    "        df = pd.read_csv(csv_path)\n",
    "\n",
    "        df_fusion = df[(df.get(\"model\") == \"fusion\") & (df.get(\"fraction\", 0) >= 0.999)]\n",
    "        if df_fusion.empty:\n",
    "            raise RuntimeError(\"æ²¡æœ‰æ‰¾åˆ° fusion æ¨¡å‹çš„å…¨é‡æ•°æ®ç»“æœï¼Œæ— æ³•è‡ªåŠ¨é€‰æ‹©æœ€ä½³ foldã€‚\")\n",
    "\n",
    "        best_row = df_fusion.sort_values(\"test_r2_mean\", ascending=False).iloc[0]\n",
    "        best_fold = int(best_row[\"fold\"])\n",
    "        best_r2 = float(best_row[\"test_r2_mean\"])\n",
    "        print(f\"ğŸŒŸ æœ€ä½³æ¨¡å‹: fusion_fold{best_fold}, RÂ²={best_r2:.3f}\")\n",
    "\n",
    "        best_model_path = os.path.join(OUT_DIR, f\"fusion_fold{best_fold}_best.pth\")\n",
    "        if os.path.exists(best_model_path):\n",
    "            infer_full_raster(\n",
    "                model_path=best_model_path,\n",
    "                out_dir=os.path.join(OUT_DIR, \"maps_2020\"),\n",
    "                step=32,\n",
    "                tag=f\"fusion_fold{best_fold}\"\n",
    "            )\n",
    "        else:\n",
    "            print(f\"âš ï¸ æœªæ‰¾åˆ°å¯¹åº”çš„æ¨¡å‹æ–‡ä»¶: {best_model_path}\")\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"âŒ è‡ªåŠ¨é€‰æ‹©æ¨¡å‹æ¨ç†å¤±è´¥: {e}\")\n",
    "        import traceback\n",
    "        traceback.print_exc()\n",
    "    \n",
    "    print(\"\\n\" + \"=\"*70)\n",
    "    print(\" ğŸ‰ æ‰€æœ‰ä»»åŠ¡å®Œæˆ!\")\n",
    "    print(\"=\"*70)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
